{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f325964",
   "metadata": {},
   "source": [
    "# RoBERTa for Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "6d6174ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import RobertaTokenizer,TFRobertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e3ac969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (8.11.0)\n",
      "Collecting ipython\n",
      "  Downloading ipython-8.13.2-py3-none-any.whl (797 kB)\n",
      "     ---------------------------------------- 0.0/797.7 kB ? eta -:--:--\n",
      "     -------- ----------------------------- 174.1/797.7 kB 3.5 MB/s eta 0:00:01\n",
      "     ------------------------- ------------ 542.7/797.7 kB 5.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- 797.7/797.7 kB 6.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: backcall in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython) (0.2.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython) (0.18.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython) (3.0.38)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython) (2.14.0)\n",
      "Requirement already satisfied: stack-data in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython) (0.6.2)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython) (5.9.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from ipython) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jedi>=0.16->ipython) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython) (0.2.6)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stack-data->ipython) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stack-data->ipython) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from stack-data->ipython) (0.2.2)\n",
      "Requirement already satisfied: six in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from asttokens>=2.1.0->stack-data->ipython) (1.16.0)\n",
      "Installing collected packages: ipython\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 8.11.0\n",
      "    Uninstalling ipython-8.11.0:\n",
      "      Successfully uninstalled ipython-8.11.0\n",
      "Successfully installed ipython-8.13.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "ed8aeeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_11_models_including_human.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "a0aae60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('all_11_methods_without_cleaning_text.csv')\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "7b4ce218",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at roberta-base were not used when initializing TFRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFRobertaModel were initialized from the model checkpoint at roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "roberta_model = TFRobertaModel.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "af073ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_roberta_embedding(sentence):\n",
    "    tokens = tokenizer.encode(sentence, max_length=512, truncation=True)\n",
    "    input_ids = tf.constant(tokens)[None, :]\n",
    "    embedding = roberta_model(input_ids)[0][0]\n",
    "    return embedding.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2af259",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_embeddings = np.vstack(tqdm(train_df['text'].apply(get_roberta_embedding)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2f7e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = np.vstack(tqdm.tqdm(test_df['text'].apply(get_roberta_embedding)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c57164",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f04c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(768,)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(11, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5148f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                   loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                   metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4cd685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train neural network classifier\n",
    "classifier.fit(train_embeddings, train_df['class'], batch_size=32, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe04f06",
   "metadata": {},
   "source": [
    "# Task 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "fb8c59cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = pd.read_csv(r\"C:\\Users\\shiny\\Downloads\\Authorship-Attribution-for-Neural-Text-Generation-master (1)\\Authorship-Attribution-for-Neural-Text-Generation-master\\data\\balanced_p2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "adf50d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = d1.drop(\"Unnamed: 0\",axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "439cd03d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bbc london the british government is expected ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>workers fight for rights at ground zero for us...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entrepreneurship and the arts the museum of mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>in coronavirus crisis tom hanks is more of a r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zunar and fahmi reza the cartoonists who helpe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2127</th>\n",
       "      <td>How much of your body is your own? this story ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2128</th>\n",
       "      <td>How do you keep a space station clean? by 1998...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2129</th>\n",
       "      <td>The city where you pay a year's rent up front ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2130</th>\n",
       "      <td>The BBC News app gives you the best of BBC New...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>Learn how the BBC is working to strengthen tru...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2132 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  class\n",
       "0     bbc london the british government is expected ...      1\n",
       "1     workers fight for rights at ground zero for us...      1\n",
       "2     entrepreneurship and the arts the museum of mo...      1\n",
       "3     in coronavirus crisis tom hanks is more of a r...      1\n",
       "4     zunar and fahmi reza the cartoonists who helpe...      1\n",
       "...                                                 ...    ...\n",
       "2127  How much of your body is your own? this story ...      0\n",
       "2128  How do you keep a space station clean? by 1998...      0\n",
       "2129  The city where you pay a year's rent up front ...      0\n",
       "2130  The BBC News app gives you the best of BBC New...      0\n",
       "2131  Learn how the BBC is working to strengthen tru...      0\n",
       "\n",
       "[2132 rows x 2 columns]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "ed36fb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = d1[\"text\"].to_frame().rename(columns={'text': 'Generation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232c4e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1_embeddings = np.vstack(T1['Generation'].apply(get_roberta_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecca28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_t1 = classifier.predict(T1_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354f1458",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1 = np.argmax(y_pred_t1,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7cbb42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a1afc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_names = label_encoder.inverse_transform(y_pred_1)\n",
    "actual = d1['class'].to_numpy()\n",
    "predictions = []\n",
    "for i in range(len(t1_names)):\n",
    "    \n",
    "    if t1_names[i] == 'human':\n",
    "        predictions.append(0)\n",
    "    else:\n",
    "        predictions.append(1)\n",
    "        \n",
    "predictions = np.array(predictions)\n",
    "print(actual)\n",
    "print(predictions)\n",
    "\n",
    "print(classification_report(actual,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd683ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb59ed0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "271a14d7",
   "metadata": {},
   "source": [
    "# POS + LSTM-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc2819a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Collecting spacy\n",
      "  Downloading spacy-3.5.2-cp311-cp311-win_amd64.whl (12.2 MB)\n",
      "     ---------------------------------------- 0.0/12.2 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.2/12.2 MB 3.3 MB/s eta 0:00:04\n",
      "     - -------------------------------------- 0.5/12.2 MB 5.9 MB/s eta 0:00:02\n",
      "     -- ------------------------------------- 0.8/12.2 MB 6.3 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 1.0/12.2 MB 6.0 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 1.3/12.2 MB 5.9 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 1.5/12.2 MB 6.0 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 1.7/12.2 MB 5.5 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 2.0/12.2 MB 5.6 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 2.3/12.2 MB 5.7 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 2.4/12.2 MB 5.5 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 2.5/12.2 MB 5.2 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 2.8/12.2 MB 5.0 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 2.8/12.2 MB 4.9 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 3.0/12.2 MB 4.8 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.2/12.2 MB 4.8 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.2/12.2 MB 4.4 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 3.9/12.2 MB 5.1 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.1/12.2 MB 5.1 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 4.5/12.2 MB 5.3 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 4.8/12.2 MB 5.2 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.2/12.2 MB 5.4 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 5.7/12.2 MB 5.6 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 6.2/12.2 MB 5.9 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 6.7/12.2 MB 6.1 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 7.2/12.2 MB 6.3 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.5/12.2 MB 6.4 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.5/12.2 MB 6.4 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.5/12.2 MB 6.4 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.5/12.2 MB 6.4 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.5/12.2 MB 6.4 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.5/12.2 MB 6.4 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.5/12.2 MB 6.4 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.5/12.2 MB 6.4 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.5/12.2 MB 6.4 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.5/12.2 MB 6.4 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 7.6/12.2 MB 4.6 MB/s eta 0:00:01\n",
      "     ------------------------- -------------- 7.9/12.2 MB 4.7 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 8.3/12.2 MB 4.8 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 8.6/12.2 MB 4.9 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.0/12.2 MB 4.9 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.4/12.2 MB 5.0 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 9.7/12.2 MB 5.1 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.1/12.2 MB 5.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 10.5/12.2 MB 5.3 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 10.9/12.2 MB 5.3 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.3/12.2 MB 5.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 11.7/12.2 MB 5.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.1/12.2 MB 5.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.2/12.2 MB 5.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.2/12.2 MB 5.5 MB/s eta 0:00:00\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.4-py3-none-any.whl (11 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Downloading murmurhash-1.0.9-cp311-cp311-win_amd64.whl (18 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Downloading cymem-2.0.7-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Downloading preshed-3.0.8-cp311-cp311-win_amd64.whl (91 kB)\n",
      "     ---------------------------------------- 0.0/91.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 91.9/91.9 kB ? eta 0:00:00\n",
      "Collecting thinc<8.2.0,>=8.1.8\n",
      "  Downloading thinc-8.1.10-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     ------- -------------------------------- 0.3/1.5 MB 5.9 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 0.7/1.5 MB 7.8 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 1.2/1.5 MB 8.2 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 8.5 MB/s eta 0:00:00\n",
      "Collecting wasabi<1.2.0,>=0.9.1\n",
      "  Downloading wasabi-1.1.1-py3-none-any.whl (27 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Downloading srsly-2.4.6-cp311-cp311-win_amd64.whl (478 kB)\n",
      "     ---------------------------------------- 0.0/478.8 kB ? eta -:--:--\n",
      "     ----------------------- ------------- 307.2/478.8 kB 18.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- 478.8/478.8 kB 10.0 MB/s eta 0:00:00\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Downloading catalogue-2.0.8-py3-none-any.whl (17 kB)\n",
      "Collecting typer<0.8.0,>=0.3.0\n",
      "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
      "Collecting pathy>=0.10.0\n",
      "  Downloading pathy-0.10.1-py3-none-any.whl (48 kB)\n",
      "     ---------------------------------------- 0.0/48.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 48.9/48.9 kB ? eta 0:00:00\n",
      "Collecting smart-open<7.0.0,>=5.2.1\n",
      "  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
      "     ---------------------------------------- 0.0/56.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 56.8/56.8 kB ? eta 0:00:00\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.23.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.28.2)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
      "  Downloading pydantic-1.10.7-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "     ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "     ------ --------------------------------- 0.3/2.1 MB 10.2 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 0.7/2.1 MB 9.5 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 1.1/2.1 MB 8.8 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 1.5/2.1 MB 8.4 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 1.8/2.1 MB 8.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 2.1/2.1 MB 8.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (23.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "     ---------------------------------------- 0.0/181.6 kB ? eta -:--:--\n",
      "     ------------------------------------- 181.6/181.6 kB 11.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
      "Collecting blis<0.8.0,>=0.7.8\n",
      "  Downloading blis-0.7.9-cp311-cp311-win_amd64.whl (7.0 MB)\n",
      "     ---------------------------------------- 0.0/7.0 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.3/7.0 MB 9.6 MB/s eta 0:00:01\n",
      "     --- ------------------------------------ 0.7/7.0 MB 8.4 MB/s eta 0:00:01\n",
      "     ----- ---------------------------------- 1.0/7.0 MB 7.8 MB/s eta 0:00:01\n",
      "     ------- -------------------------------- 1.4/7.0 MB 8.0 MB/s eta 0:00:01\n",
      "     --------- ------------------------------ 1.6/7.0 MB 7.4 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 2.1/7.0 MB 8.0 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 2.4/7.0 MB 7.7 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 2.8/7.0 MB 7.7 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 3.1/7.0 MB 8.0 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 3.5/7.0 MB 8.0 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 3.8/7.0 MB 7.9 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 4.3/7.0 MB 8.0 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 4.6/7.0 MB 7.9 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 4.8/7.0 MB 7.8 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 4.8/7.0 MB 7.8 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 4.8/7.0 MB 7.8 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 4.8/7.0 MB 7.8 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 4.8/7.0 MB 7.8 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 4.8/7.0 MB 7.8 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 4.8/7.0 MB 7.8 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 4.8/7.0 MB 7.8 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 4.8/7.0 MB 7.8 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 4.8/7.0 MB 7.8 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 4.8/7.0 MB 7.8 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 4.8/7.0 MB 4.2 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 4.9/7.0 MB 4.1 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 5.0/7.0 MB 4.1 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 5.3/7.0 MB 4.2 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 5.5/7.0 MB 4.2 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 5.9/7.0 MB 4.3 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 6.1/7.0 MB 4.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 6.5/7.0 MB 4.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 6.8/7.0 MB 4.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 7.0/7.0 MB 4.6 MB/s eta 0:00:00\n",
      "Collecting confection<1.0.0,>=0.0.1\n",
      "  Downloading confection-0.0.4-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy) (2.1.2)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, smart-open, pydantic, murmurhash, langcodes, catalogue, blis, typer, srsly, preshed, pathy, confection, thinc, spacy\n",
      "Successfully installed blis-0.7.9 catalogue-2.0.8 confection-0.0.4 cymem-2.0.7 langcodes-3.3.0 murmurhash-1.0.9 pathy-0.10.1 preshed-3.0.8 pydantic-1.10.7 smart-open-6.3.0 spacy-3.5.2 spacy-legacy-3.0.12 spacy-loggers-1.0.4 srsly-2.4.6 thinc-8.1.10 typer-0.7.0 wasabi-1.1.1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "eadd6492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, Flatten, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55f916b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.5.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.2/12.8 MB 7.3 MB/s eta 0:00:02\n",
      "     -- ------------------------------------- 0.7/12.8 MB 8.7 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 1.0/12.8 MB 8.1 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 1.4/12.8 MB 7.8 MB/s eta 0:00:02\n",
      "     ----- ---------------------------------- 1.8/12.8 MB 8.2 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 2.3/12.8 MB 8.7 MB/s eta 0:00:02\n",
      "     -------- ------------------------------- 2.8/12.8 MB 8.8 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 3.1/12.8 MB 8.7 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 3.6/12.8 MB 9.0 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 4.0/12.8 MB 9.2 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 4.0/12.8 MB 8.9 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 4.0/12.8 MB 8.9 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 4.0/12.8 MB 8.9 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 4.1/12.8 MB 6.3 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.2/12.8 MB 6.2 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.4/12.8 MB 6.1 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 4.6/12.8 MB 6.0 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 4.8/12.8 MB 6.0 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 5.0/12.8 MB 6.0 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 5.4/12.8 MB 5.9 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 5.8/12.8 MB 6.1 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 6.3/12.8 MB 6.3 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 6.9/12.8 MB 6.6 MB/s eta 0:00:01\n",
      "     ----------------------- ---------------- 7.4/12.8 MB 6.8 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 8.0/12.8 MB 7.0 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 8.6/12.8 MB 7.2 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.1/12.8 MB 7.4 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.7/12.8 MB 7.6 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.2/12.8 MB 7.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 7.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 7.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 7.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 7.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 7.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 7.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 7.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 7.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 7.9 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 6.0 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.8/12.8 MB 5.8 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.2/12.8 MB 5.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.6/12.8 MB 5.8 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 11.9/12.8 MB 5.8 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.4/12.8 MB 5.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 5.8 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 5.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from en-core-web-sm==3.5.0) (3.5.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
      "Requirement already satisfied: pathy>=0.10.0 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.23.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.28.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shiny\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.5.0\n",
      "\u001b[38;5;2m[+] Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "368be163",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ef6975b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('all_11_methods_without_cleaning_text.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf606f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generation</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['News Latest Headlines on CNN Business \\n TL;...</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"News China wants to take a victory lap over ...</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"News Coronavirus disinformation creates chal...</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"News China coronavirus: Eating wild animals ...</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"News China's economy could shrink for the fi...</td>\n",
       "      <td>ctrl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11721</th>\n",
       "      <td>\"How much of your body is your own?\"\"\" \"\" \"All...</td>\n",
       "      <td>instructgpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11722</th>\n",
       "      <td>\"How do you keep a space station clean?\"\"\" \"\" ...</td>\n",
       "      <td>instructgpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11723</th>\n",
       "      <td>\"The city where you pay a year's rent up front...</td>\n",
       "      <td>instructgpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11724</th>\n",
       "      <td>\"The BBC News app gives you the best of BBC Ne...</td>\n",
       "      <td>instructgpt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11725</th>\n",
       "      <td>\"Learn how the BBC is working to strengthen tr...</td>\n",
       "      <td>instructgpt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11726 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Generation        label\n",
       "0      ['News Latest Headlines on CNN Business \\n TL;...         ctrl\n",
       "1      [\"News China wants to take a victory lap over ...         ctrl\n",
       "2      [\"News Coronavirus disinformation creates chal...         ctrl\n",
       "3      [\"News China coronavirus: Eating wild animals ...         ctrl\n",
       "4      [\"News China's economy could shrink for the fi...         ctrl\n",
       "...                                                  ...          ...\n",
       "11721  \"How much of your body is your own?\"\"\" \"\" \"All...  instructgpt\n",
       "11722  \"How do you keep a space station clean?\"\"\" \"\" ...  instructgpt\n",
       "11723  \"The city where you pay a year's rent up front...  instructgpt\n",
       "11724  \"The BBC News app gives you the best of BBC Ne...  instructgpt\n",
       "11725  \"Learn how the BBC is working to strengthen tr...  instructgpt\n",
       "\n",
       "[11726 rows x 2 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(\"Unnamed: 0\",axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbdf11e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^a-zA-Z0-9\\s]', '',text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da575c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(text):\n",
    "    doc = nlp(text)\n",
    "    pos_tags = [token.pos_ for token in doc]\n",
    "    named_entities = [ent.label_ for ent in doc.ents]\n",
    "    dep_tags = [token.dep_ for token in doc]\n",
    "    features = pos_tags + named_entities + dep_tags\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5dd0efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Generation'] = df['Generation'].apply(preprocess)\n",
    "df['Features'] = df['Generation'].apply(extract_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "517b7115",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Features'] = df['Features'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "ff29cbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(df['Features'])\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "450eec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "688836d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_tfidf, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "90d30998",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = X_train_tfidf.shape[1]\n",
    "input_shape = (max_len,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9d508d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=input_shape),\n",
    "    tf.keras.layers.Reshape((max_len, 1)),\n",
    "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
    "    tf.keras.layers.LSTM(64),\n",
    "    tf.keras.layers.Dense(len(le.classes_), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "92ea1041",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "d4e23f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "235/235 [==============================] - 11s 35ms/step - loss: 2.2118 - accuracy: 0.1890 - val_loss: 1.8671 - val_accuracy: 0.3230\n",
      "Epoch 2/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 1.6438 - accuracy: 0.3910 - val_loss: 1.5662 - val_accuracy: 0.4483\n",
      "Epoch 3/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 1.5187 - accuracy: 0.4443 - val_loss: 1.5921 - val_accuracy: 0.4286\n",
      "Epoch 4/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 1.4749 - accuracy: 0.4570 - val_loss: 1.4679 - val_accuracy: 0.4728\n",
      "Epoch 5/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 1.4236 - accuracy: 0.4775 - val_loss: 1.4009 - val_accuracy: 0.4845\n",
      "Epoch 6/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 1.3513 - accuracy: 0.5055 - val_loss: 1.4075 - val_accuracy: 0.4851\n",
      "Epoch 7/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 1.3209 - accuracy: 0.5201 - val_loss: 1.3951 - val_accuracy: 0.4797\n",
      "Epoch 8/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 1.2858 - accuracy: 0.5263 - val_loss: 1.3980 - val_accuracy: 0.4829\n",
      "Epoch 9/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 1.2645 - accuracy: 0.5368 - val_loss: 1.3008 - val_accuracy: 0.5075\n",
      "Epoch 10/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 1.2292 - accuracy: 0.5505 - val_loss: 1.3979 - val_accuracy: 0.4867\n",
      "Epoch 11/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 1.2019 - accuracy: 0.5600 - val_loss: 1.2833 - val_accuracy: 0.5373\n",
      "Epoch 12/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 1.1908 - accuracy: 0.5662 - val_loss: 1.1687 - val_accuracy: 0.5874\n",
      "Epoch 13/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 1.1385 - accuracy: 0.5830 - val_loss: 1.1403 - val_accuracy: 0.5842\n",
      "Epoch 14/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 1.0742 - accuracy: 0.6131 - val_loss: 1.0799 - val_accuracy: 0.6061\n",
      "Epoch 15/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 1.0744 - accuracy: 0.6062 - val_loss: 1.0876 - val_accuracy: 0.6055\n",
      "Epoch 16/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 1.0191 - accuracy: 0.6274 - val_loss: 1.1506 - val_accuracy: 0.5778\n",
      "Epoch 17/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.9962 - accuracy: 0.6418 - val_loss: 1.0648 - val_accuracy: 0.6173\n",
      "Epoch 18/60\n",
      "235/235 [==============================] - 8s 34ms/step - loss: 0.9862 - accuracy: 0.6446 - val_loss: 1.0717 - val_accuracy: 0.6082\n",
      "Epoch 19/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.9529 - accuracy: 0.6562 - val_loss: 0.9999 - val_accuracy: 0.6338\n",
      "Epoch 20/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.9431 - accuracy: 0.6588 - val_loss: 1.0091 - val_accuracy: 0.6359\n",
      "Epoch 21/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.9250 - accuracy: 0.6624 - val_loss: 0.9852 - val_accuracy: 0.6359\n",
      "Epoch 22/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.9032 - accuracy: 0.6739 - val_loss: 0.9388 - val_accuracy: 0.6477\n",
      "Epoch 23/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.8706 - accuracy: 0.6826 - val_loss: 0.9540 - val_accuracy: 0.6450\n",
      "Epoch 24/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.8798 - accuracy: 0.6815 - val_loss: 0.9886 - val_accuracy: 0.6343\n",
      "Epoch 25/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.8550 - accuracy: 0.6882 - val_loss: 0.9728 - val_accuracy: 0.6477\n",
      "Epoch 26/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.8482 - accuracy: 0.6903 - val_loss: 1.0057 - val_accuracy: 0.6263\n",
      "Epoch 27/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.8252 - accuracy: 0.6987 - val_loss: 0.9207 - val_accuracy: 0.6620\n",
      "Epoch 28/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.8136 - accuracy: 0.7002 - val_loss: 0.9832 - val_accuracy: 0.6429\n",
      "Epoch 29/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.8131 - accuracy: 0.6994 - val_loss: 0.9819 - val_accuracy: 0.6386\n",
      "Epoch 30/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.8053 - accuracy: 0.7051 - val_loss: 0.9155 - val_accuracy: 0.6642\n",
      "Epoch 31/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.7879 - accuracy: 0.7108 - val_loss: 0.8834 - val_accuracy: 0.6791\n",
      "Epoch 32/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.7744 - accuracy: 0.7126 - val_loss: 0.9030 - val_accuracy: 0.6706\n",
      "Epoch 33/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.7662 - accuracy: 0.7111 - val_loss: 0.8448 - val_accuracy: 0.6892\n",
      "Epoch 34/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.7617 - accuracy: 0.7223 - val_loss: 0.8682 - val_accuracy: 0.6722\n",
      "Epoch 35/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.7477 - accuracy: 0.7203 - val_loss: 0.8851 - val_accuracy: 0.6738\n",
      "Epoch 36/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.7423 - accuracy: 0.7287 - val_loss: 0.8358 - val_accuracy: 0.6956\n",
      "Epoch 37/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.7274 - accuracy: 0.7324 - val_loss: 0.8747 - val_accuracy: 0.6706\n",
      "Epoch 38/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.7248 - accuracy: 0.7291 - val_loss: 0.8558 - val_accuracy: 0.6855\n",
      "Epoch 39/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.7158 - accuracy: 0.7344 - val_loss: 0.8511 - val_accuracy: 0.6892\n",
      "Epoch 40/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.7243 - accuracy: 0.7340 - val_loss: 0.8205 - val_accuracy: 0.6983\n",
      "Epoch 41/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.6966 - accuracy: 0.7387 - val_loss: 0.8115 - val_accuracy: 0.6951\n",
      "Epoch 42/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.7013 - accuracy: 0.7441 - val_loss: 0.9074 - val_accuracy: 0.6716\n",
      "Epoch 43/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.7031 - accuracy: 0.7396 - val_loss: 0.8799 - val_accuracy: 0.6759\n",
      "Epoch 44/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.6887 - accuracy: 0.7463 - val_loss: 0.8392 - val_accuracy: 0.6908\n",
      "Epoch 45/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.6764 - accuracy: 0.7520 - val_loss: 0.8382 - val_accuracy: 0.6924\n",
      "Epoch 46/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.6664 - accuracy: 0.7480 - val_loss: 0.8272 - val_accuracy: 0.6935\n",
      "Epoch 47/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.6710 - accuracy: 0.7485 - val_loss: 0.8515 - val_accuracy: 0.6866\n",
      "Epoch 48/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.6585 - accuracy: 0.7537 - val_loss: 0.8127 - val_accuracy: 0.7026\n",
      "Epoch 49/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.6641 - accuracy: 0.7533 - val_loss: 0.8639 - val_accuracy: 0.6850\n",
      "Epoch 50/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.6483 - accuracy: 0.7556 - val_loss: 0.8244 - val_accuracy: 0.7111\n",
      "Epoch 51/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.6410 - accuracy: 0.7613 - val_loss: 0.8439 - val_accuracy: 0.6935\n",
      "Epoch 52/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.6365 - accuracy: 0.7624 - val_loss: 0.8264 - val_accuracy: 0.7058\n",
      "Epoch 53/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.6325 - accuracy: 0.7605 - val_loss: 0.8306 - val_accuracy: 0.7004\n",
      "Epoch 54/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.6311 - accuracy: 0.7607 - val_loss: 0.8250 - val_accuracy: 0.6972\n",
      "Epoch 55/60\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.6194 - accuracy: 0.7663 - val_loss: 0.8359 - val_accuracy: 0.7058\n",
      "Epoch 56/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.6132 - accuracy: 0.7728 - val_loss: 0.9179 - val_accuracy: 0.6674\n",
      "Epoch 57/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.6180 - accuracy: 0.7695 - val_loss: 0.8285 - val_accuracy: 0.7036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.6083 - accuracy: 0.7705 - val_loss: 0.8437 - val_accuracy: 0.7036\n",
      "Epoch 59/60\n",
      "235/235 [==============================] - 7s 32ms/step - loss: 0.6148 - accuracy: 0.7684 - val_loss: 0.8060 - val_accuracy: 0.7095\n",
      "Epoch 60/60\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.5820 - accuracy: 0.7856 - val_loss: 0.8776 - val_accuracy: 0.6892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20c37006450>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train.toarray(), y_train, epochs=60, batch_size=32, validation_data=(X_val.toarray(), y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "0669ecf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 1s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "fb4b611c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 8, 4, ..., 3, 0, 4], dtype=int64)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c539879e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  5,  4, ...,  3, 10,  4])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "004d384d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[210   1   0   0   0   0   0   0   0   0   3]\n",
      " [  0  88   1  30   7  53   6  10  13   1   0]\n",
      " [ 11   0 201   0   1   0   3   0   1   0   0]\n",
      " [  0  48   0 124  10  14   1  11   3   1   1]\n",
      " [  0   5   3   2 111   3  21  41  28   1   2]\n",
      " [  1  44   0   6   2 137   7  16   6   0   3]\n",
      " [  1   3   3   0  32   3 138   9  29   1   1]\n",
      " [  1  10   0  11  29   8  13 101  26   3   0]\n",
      " [  0   0   0   0  17   1  14  10 164   0   0]\n",
      " [  4   0   1   0   0   0   0   2   0 195  13]\n",
      " [ 36   0   5   0   2   0   0   1   1   1 165]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "4a4159d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ctrl       0.80      0.98      0.88       214\n",
      "        fair       0.44      0.42      0.43       209\n",
      "         gpt       0.94      0.93      0.93       217\n",
      "        gpt2       0.72      0.58      0.64       213\n",
      "        gpt3       0.53      0.51      0.52       217\n",
      "      grover       0.63      0.62      0.62       222\n",
      "       human       0.68      0.63      0.65       220\n",
      " instructgpt       0.50      0.50      0.50       202\n",
      "        pplm       0.61      0.80      0.69       206\n",
      "         xlm       0.96      0.91      0.93       215\n",
      "       xlnet       0.88      0.78      0.83       211\n",
      "\n",
      "    accuracy                           0.70      2346\n",
      "   macro avg       0.70      0.70      0.69      2346\n",
      "weighted avg       0.70      0.70      0.69      2346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "9d18a026",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('POS_LSTM_LSTM.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac35ad4c",
   "metadata": {},
   "source": [
    "# Task - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "bbaa18b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = pd.read_csv(r\"C:\\Users\\shiny\\Downloads\\Authorship-Attribution-for-Neural-Text-Generation-master (1)\\Authorship-Attribution-for-Neural-Text-Generation-master\\Clean_Generated\\task_3_data_without_cleaning.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "69791d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d2 = d2.drop(\"Unnamed: 0\",axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "aab0b134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ctrl           500\n",
       "gpt            500\n",
       "gpt2           500\n",
       "grover         500\n",
       "xlm            500\n",
       "xlnet          500\n",
       "pplm           500\n",
       "fair           500\n",
       "gpt3           500\n",
       "instructgpt    500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d2['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "1b69faf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1 = d2[\"Generation\"].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "a9b45c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['News Latest Headlines on CNN Business \\n TL;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"News China wants to take a victory lap over ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"News Coronavirus disinformation creates chal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"News China coronavirus: Eating wild animals ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"News China's economy could shrink for the fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>\"One dead in suicide bomb attack near US embas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>\"Nigeria says it is ready and more than capabl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>\"Lesotho Prime Minister in surprise court appe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>\"Dutch government returns stolen 18th-century ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>\"Here are the African countries with confirmed...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Generation\n",
       "0     ['News Latest Headlines on CNN Business \\n TL;...\n",
       "1     [\"News China wants to take a victory lap over ...\n",
       "2     [\"News Coronavirus disinformation creates chal...\n",
       "3     [\"News China coronavirus: Eating wild animals ...\n",
       "4     [\"News China's economy could shrink for the fi...\n",
       "...                                                 ...\n",
       "4995  \"One dead in suicide bomb attack near US embas...\n",
       "4996  \"Nigeria says it is ready and more than capabl...\n",
       "4997  \"Lesotho Prime Minister in surprise court appe...\n",
       "4998  \"Dutch government returns stolen 18th-century ...\n",
       "4999  \"Here are the African countries with confirmed...\n",
       "\n",
       "[5000 rows x 1 columns]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "27d5193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "T1['Generation'] = T1['Generation'].apply(preprocess)\n",
    "T1['Features'] = T1['Generation'].apply(extract_features)\n",
    "T1['Features'] = T1['Features'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "5abaacf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Generation</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news latest headlines on cnn business n tldr t...</td>\n",
       "      <td>NOUN ADJ NOUN ADP PROPN NOUN VERB VERB DET PRO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>news china wants to take a victory lap over it...</td>\n",
       "      <td>PROPN PROPN VERB PART VERB DET NOUN NOUN ADP P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news coronavirus disinformation creates challe...</td>\n",
       "      <td>NOUN NOUN NOUN VERB NOUN ADP PROPN PROPN PROPN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news china coronavirus eating wild animals mad...</td>\n",
       "      <td>NOUN PROPN PROPN VERB ADJ NOUN VERB ADJ CCONJ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news chinas economy could shrink for the first...</td>\n",
       "      <td>NOUN PROPN PROPN AUX VERB ADP DET ADJ NOUN ADP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>one dead in suicide bomb attack near us embass...</td>\n",
       "      <td>NUM ADJ ADP NOUN NOUN NOUN ADP PROPN NOUN ADP ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>nigeria says it is ready and more than capable...</td>\n",
       "      <td>PROPN VERB PRON AUX ADJ CCONJ ADJ ADP ADJ ADP ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>lesotho prime minister in surprise court appea...</td>\n",
       "      <td>PROPN PROPN PROPN ADP NOUN NOUN NOUN SCONJ NOU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>dutch government returns stolen 18thcentury pr...</td>\n",
       "      <td>ADJ NOUN NOUN VERB NUM ADJ NOUN ADP NOUN SPACE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>here are the african countries with confirmed ...</td>\n",
       "      <td>ADV AUX DET ADJ NOUN ADP VERB PROPN NOUN ADP P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Generation  \\\n",
       "0     news latest headlines on cnn business n tldr t...   \n",
       "1     news china wants to take a victory lap over it...   \n",
       "2     news coronavirus disinformation creates challe...   \n",
       "3     news china coronavirus eating wild animals mad...   \n",
       "4     news chinas economy could shrink for the first...   \n",
       "...                                                 ...   \n",
       "4995  one dead in suicide bomb attack near us embass...   \n",
       "4996  nigeria says it is ready and more than capable...   \n",
       "4997  lesotho prime minister in surprise court appea...   \n",
       "4998  dutch government returns stolen 18thcentury pr...   \n",
       "4999  here are the african countries with confirmed ...   \n",
       "\n",
       "                                               Features  \n",
       "0     NOUN ADJ NOUN ADP PROPN NOUN VERB VERB DET PRO...  \n",
       "1     PROPN PROPN VERB PART VERB DET NOUN NOUN ADP P...  \n",
       "2     NOUN NOUN NOUN VERB NOUN ADP PROPN PROPN PROPN...  \n",
       "3     NOUN PROPN PROPN VERB ADJ NOUN VERB ADJ CCONJ ...  \n",
       "4     NOUN PROPN PROPN AUX VERB ADP DET ADJ NOUN ADP...  \n",
       "...                                                 ...  \n",
       "4995  NUM ADJ ADP NOUN NOUN NOUN ADP PROPN NOUN ADP ...  \n",
       "4996  PROPN VERB PRON AUX ADJ CCONJ ADJ ADP ADJ ADP ...  \n",
       "4997  PROPN PROPN PROPN ADP NOUN NOUN NOUN SCONJ NOU...  \n",
       "4998  ADJ NOUN NOUN VERB NUM ADJ NOUN ADP NOUN SPACE...  \n",
       "4999  ADV AUX DET ADJ NOUN ADP VERB PROPN NOUN ADP P...  \n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "ca5116df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(T1['Features'])\n",
    "X_test = tfidf_transformer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "64bf1481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 3s 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ...,  7,  8, 10], dtype=int64)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model('POS_LSTM_LSTM.h5')\n",
    "y_pred = loaded_model.predict(X_test.toarray())\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "501804d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = le.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "28a005df",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = d2['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "895b6eef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ctrl' 'ctrl' 'ctrl' ... 'instructgpt' 'instructgpt' 'instructgpt']\n",
      "['ctrl' 'ctrl' 'ctrl' ... 'instructgpt' 'pplm' 'xlnet']\n"
     ]
    }
   ],
   "source": [
    "print(actual)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "17d110cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ctrl       0.80      0.98      0.88       500\n",
      "        fair       0.51      0.45      0.48       500\n",
      "         gpt       0.96      0.93      0.95       500\n",
      "        gpt2       0.78      0.61      0.69       500\n",
      "      grover       0.64      0.70      0.67       500\n",
      " instructgpt       0.63      0.61      0.62       500\n",
      "        pplm       0.72      0.85      0.78       500\n",
      "         xlm       0.98      0.93      0.95       500\n",
      "       xlnet       0.92      0.80      0.85       500\n",
      "        gpt3       0.72      0.59      0.65       500\n",
      " instructgpt       0.63      0.61      0.62       500\n",
      "\n",
      "   micro avg       0.75      0.73      0.74      5500\n",
      "   macro avg       0.75      0.73      0.74      5500\n",
      "weighted avg       0.75      0.73      0.74      5500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(actual, y_pred, labels=['ctrl','fair','gpt','gpt2','grover','instructgpt','pplm','xlm','xlnet','gpt3', 'instructgpt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08428016",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48179f6d",
   "metadata": {},
   "source": [
    "# POS + Stacked CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "efae966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(df['Features'])\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e0bc97e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "712b2f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_tfidf, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "baf86c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = X_train_tfidf.shape[1]\n",
    "input_shape = (max_len,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "341e6c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=input_shape),\n",
    "    tf.keras.layers.Reshape((max_len, 1)),\n",
    "    tf.keras.layers.Conv1D(64, kernel_size=3, padding=\"valid\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv1D(64, kernel_size=4, padding=\"valid\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv1D(64, kernel_size=5, padding=\"valid\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv1D(64, kernel_size=6, padding=\"valid\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv1D(64, kernel_size=7, padding=\"valid\", activation=\"relu\"),\n",
    "    tf.keras.layers.Conv1D(64, kernel_size=8, padding=\"valid\", activation=\"relu\"),\n",
    "    tf.keras.layers.GlobalMaxPooling1D(),\n",
    "    tf.keras.layers.Dense(len(le.classes_), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "07c5f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a7112852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "235/235 [==============================] - 10s 32ms/step - loss: 1.7446 - accuracy: 0.3755 - val_loss: 1.3748 - val_accuracy: 0.4963\n",
      "Epoch 2/15\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 1.0119 - accuracy: 0.6307 - val_loss: 0.9602 - val_accuracy: 0.6509\n",
      "Epoch 3/15\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.8478 - accuracy: 0.6871 - val_loss: 0.8047 - val_accuracy: 0.6994\n",
      "Epoch 4/15\n",
      "235/235 [==============================] - 7s 30ms/step - loss: 0.7733 - accuracy: 0.7170 - val_loss: 0.7347 - val_accuracy: 0.7287\n",
      "Epoch 5/15\n",
      "235/235 [==============================] - 9s 37ms/step - loss: 0.7099 - accuracy: 0.7328 - val_loss: 0.6903 - val_accuracy: 0.7473\n",
      "Epoch 6/15\n",
      "235/235 [==============================] - 8s 34ms/step - loss: 0.6529 - accuracy: 0.7611 - val_loss: 0.6691 - val_accuracy: 0.7479\n",
      "Epoch 7/15\n",
      "235/235 [==============================] - 7s 31ms/step - loss: 0.6349 - accuracy: 0.7629 - val_loss: 0.7262 - val_accuracy: 0.7116\n",
      "Epoch 8/15\n",
      "235/235 [==============================] - 9s 36ms/step - loss: 0.6129 - accuracy: 0.7699 - val_loss: 0.7073 - val_accuracy: 0.7351\n",
      "Epoch 9/15\n",
      "235/235 [==============================] - 7s 32ms/step - loss: 0.5697 - accuracy: 0.7881 - val_loss: 0.6344 - val_accuracy: 0.7687\n",
      "Epoch 10/15\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.5595 - accuracy: 0.7868 - val_loss: 0.6457 - val_accuracy: 0.7575\n",
      "Epoch 11/15\n",
      "235/235 [==============================] - 9s 37ms/step - loss: 0.5346 - accuracy: 0.7976 - val_loss: 0.6437 - val_accuracy: 0.7585\n",
      "Epoch 12/15\n",
      "235/235 [==============================] - 8s 33ms/step - loss: 0.5197 - accuracy: 0.8022 - val_loss: 0.6929 - val_accuracy: 0.7484\n",
      "Epoch 13/15\n",
      "235/235 [==============================] - 9s 39ms/step - loss: 0.5089 - accuracy: 0.8094 - val_loss: 0.6538 - val_accuracy: 0.7612\n",
      "Epoch 14/15\n",
      "235/235 [==============================] - 8s 32ms/step - loss: 0.4869 - accuracy: 0.8140 - val_loss: 0.7163 - val_accuracy: 0.7260\n",
      "Epoch 15/15\n",
      "235/235 [==============================] - 7s 32ms/step - loss: 0.4677 - accuracy: 0.8209 - val_loss: 0.6675 - val_accuracy: 0.7532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20c21d4f850>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train.toarray(), y_train, epochs=15, batch_size=32, validation_data=(X_val.toarray(), y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "12216fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 1s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8c2eb50d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4,  3,  4, ...,  3, 10,  4], dtype=int64)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "22c3653e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  5,  4, ...,  3, 10,  4])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "76ca11d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[211   2   0   0   0   0   0   0   0   0   1]\n",
      " [  0  75   0  63   7  53   1   9   1   0   0]\n",
      " [  1   0 208   0   3   2   2   1   0   0   0]\n",
      " [  0  21   0 170   1   9   6   6   0   0   0]\n",
      " [  0   0   0   3 133   1  20  57   3   0   0]\n",
      " [  0  17   0  27   1 167   0   5   3   0   2]\n",
      " [  0   9   1   3  33  25 121   9  19   0   0]\n",
      " [  1   3   0  17  43   5   3 126   4   0   0]\n",
      " [  0  10   0   3  23  10   3  14 143   0   0]\n",
      " [  1   1   0   5   0   0   1   1   2 204   0]\n",
      " [  9   1   0   2   0   1   0   0   1   0 197]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b39029d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ctrl       0.95      0.99      0.97       214\n",
      "        fair       0.54      0.36      0.43       209\n",
      "         gpt       1.00      0.96      0.98       217\n",
      "        gpt2       0.58      0.80      0.67       213\n",
      "        gpt3       0.55      0.61      0.58       217\n",
      "      grover       0.61      0.75      0.67       222\n",
      "       human       0.77      0.55      0.64       220\n",
      " instructgpt       0.55      0.62      0.59       202\n",
      "        pplm       0.81      0.69      0.75       206\n",
      "         xlm       1.00      0.95      0.97       215\n",
      "       xlnet       0.98      0.93      0.96       211\n",
      "\n",
      "    accuracy                           0.75      2346\n",
      "   macro avg       0.76      0.75      0.75      2346\n",
      "weighted avg       0.76      0.75      0.75      2346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4606f58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('POS_Stacked_CNN.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4700433b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c00592c",
   "metadata": {},
   "source": [
    "# Task - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "9e469110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 5, ..., 7, 7, 4], dtype=int64)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model('POS_Stacked_CNN.h5')\n",
    "y_pred = loaded_model.predict(X_test.toarray())\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "f4608d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = le.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "42dec655",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = d2['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "78433a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ctrl' 'ctrl' 'ctrl' ... 'instructgpt' 'instructgpt' 'instructgpt']\n",
      "['ctrl' 'ctrl' 'grover' ... 'instructgpt' 'instructgpt' 'gpt3']\n"
     ]
    }
   ],
   "source": [
    "print(actual)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "f85859e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ctrl       0.97      0.99      0.98       500\n",
      "        fair       0.68      0.43      0.53       500\n",
      "         gpt       1.00      0.97      0.98       500\n",
      "        gpt2       0.64      0.85      0.73       500\n",
      "      grover       0.71      0.81      0.75       500\n",
      " instructgpt       0.74      0.73      0.74       500\n",
      "        pplm       0.92      0.77      0.84       500\n",
      "         xlm       1.00      0.98      0.99       500\n",
      "       xlnet       1.00      0.97      0.98       500\n",
      "        gpt3       0.73      0.76      0.74       500\n",
      " instructgpt       0.74      0.73      0.74       500\n",
      "\n",
      "   micro avg       0.83      0.82      0.82      5500\n",
      "   macro avg       0.83      0.82      0.82      5500\n",
      "weighted avg       0.83      0.82      0.82      5500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(actual, y_pred, labels=['ctrl','fair','gpt','gpt2','grover','instructgpt','pplm','xlm','xlnet','gpt3', 'instructgpt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1dc984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72b447f1",
   "metadata": {},
   "source": [
    "# POS + CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ddb7e660",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(df['Features'])\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f5655156",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e6790942",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_tfidf, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9e4b0229",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = X_train_tfidf.shape[1]\n",
    "input_shape = (max_len,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "d0b0087c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=input_shape),\n",
    "    tf.keras.layers.Reshape((max_len, 1)),\n",
    "    tf.keras.layers.Conv1D(32, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
    "    tf.keras.layers.LSTM(64),\n",
    "    tf.keras.layers.Dense(len(le.classes_), activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c9fc0620",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9d344d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "235/235 [==============================] - 5s 22ms/step - loss: 0.8346 - accuracy: 0.6906 - val_loss: 0.9967 - val_accuracy: 0.6343\n",
      "Epoch 2/10\n",
      "235/235 [==============================] - 5s 22ms/step - loss: 0.8359 - accuracy: 0.6867 - val_loss: 0.9026 - val_accuracy: 0.6743\n",
      "Epoch 3/10\n",
      "235/235 [==============================] - 5s 22ms/step - loss: 0.8164 - accuracy: 0.6955 - val_loss: 0.9016 - val_accuracy: 0.6652\n",
      "Epoch 4/10\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.8212 - accuracy: 0.6887 - val_loss: 0.9204 - val_accuracy: 0.6557\n",
      "Epoch 5/10\n",
      "235/235 [==============================] - 5s 22ms/step - loss: 0.8104 - accuracy: 0.6955 - val_loss: 0.8692 - val_accuracy: 0.6839\n",
      "Epoch 6/10\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.7862 - accuracy: 0.7030 - val_loss: 0.8565 - val_accuracy: 0.6818\n",
      "Epoch 7/10\n",
      "235/235 [==============================] - 5s 22ms/step - loss: 0.7935 - accuracy: 0.7008 - val_loss: 0.9179 - val_accuracy: 0.6663\n",
      "Epoch 8/10\n",
      "235/235 [==============================] - 5s 22ms/step - loss: 0.7820 - accuracy: 0.7015 - val_loss: 0.8882 - val_accuracy: 0.6674\n",
      "Epoch 9/10\n",
      "235/235 [==============================] - 5s 22ms/step - loss: 0.7739 - accuracy: 0.7088 - val_loss: 0.8611 - val_accuracy: 0.6834\n",
      "Epoch 10/10\n",
      "235/235 [==============================] - 5s 22ms/step - loss: 0.7750 - accuracy: 0.7079 - val_loss: 0.9159 - val_accuracy: 0.6535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20c28076990>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train.toarray(), y_train, epochs=10, batch_size=32, validation_data=(X_val.toarray(), y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "55b36a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 8s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0db2139d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  4,  4, ...,  1, 10,  4], dtype=int64)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d6ee1870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  5,  4, ...,  3, 10,  4])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "45a3cd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[207   0   1   0   0   0   0   0   0   1   5]\n",
      " [  1  63   0  67  15  44   5   8   3   3   0]\n",
      " [  1   0 209   0   0   3   4   0   0   0   0]\n",
      " [  0  30   0 140  23   7   0   7   2   4   0]\n",
      " [  0   2   1   8 156   2  10  31   5   2   0]\n",
      " [  1  41   0  15  11 137   0  13   2   0   2]\n",
      " [  1   3   2   5  59  11 119  10   9   1   0]\n",
      " [  1   1   0  19  99   7   7  62   4   1   1]\n",
      " [  0   4   0   1  70   5  13   6 107   0   0]\n",
      " [  3   0   0   0   0   0   0   0   6 206   0]\n",
      " [ 14   0   2   0   0   0   0   1   1   9 184]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1259b45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ctrl       0.90      0.97      0.93       214\n",
      "        fair       0.44      0.30      0.36       209\n",
      "         gpt       0.97      0.96      0.97       217\n",
      "        gpt2       0.55      0.66      0.60       213\n",
      "        gpt3       0.36      0.72      0.48       217\n",
      "      grover       0.63      0.62      0.63       222\n",
      "       human       0.75      0.54      0.63       220\n",
      " instructgpt       0.45      0.31      0.36       202\n",
      "        pplm       0.77      0.52      0.62       206\n",
      "         xlm       0.91      0.96      0.93       215\n",
      "       xlnet       0.96      0.87      0.91       211\n",
      "\n",
      "    accuracy                           0.68      2346\n",
      "   macro avg       0.70      0.67      0.67      2346\n",
      "weighted avg       0.70      0.68      0.68      2346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fd5cba14",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('POS_CNN_LSTM.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719e85d0",
   "metadata": {},
   "source": [
    "# Task - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "9c38a5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 1s 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 9, ..., 4, 4, 9], dtype=int64)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model('POS_CNN_LSTM.h5')\n",
    "y_pred = loaded_model.predict(X_test.toarray())\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "c462db01",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = le.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "dcdd62af",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = d2['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "2e36cffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ctrl' 'ctrl' 'ctrl' ... 'instructgpt' 'instructgpt' 'instructgpt']\n",
      "['ctrl' 'ctrl' 'xlm' ... 'gpt3' 'gpt3' 'xlm']\n"
     ]
    }
   ],
   "source": [
    "print(actual)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "171515b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ctrl       0.95      0.96      0.95       500\n",
      "        fair       0.47      0.33      0.39       500\n",
      "         gpt       0.97      0.98      0.97       500\n",
      "        gpt2       0.59      0.70      0.64       500\n",
      "      grover       0.62      0.60      0.61       500\n",
      " instructgpt       0.52      0.35      0.42       500\n",
      "        pplm       0.86      0.47      0.61       500\n",
      "         xlm       0.92      0.96      0.94       500\n",
      "       xlnet       0.96      0.91      0.93       500\n",
      "        gpt3       0.41      0.72      0.52       500\n",
      " instructgpt       0.52      0.35      0.42       500\n",
      "\n",
      "   micro avg       0.70      0.66      0.68      5500\n",
      "   macro avg       0.71      0.66      0.67      5500\n",
      "weighted avg       0.71      0.66      0.67      5500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(actual, y_pred, labels=['ctrl','fair','gpt','gpt2','grover','instructgpt','pplm','xlm','xlnet','gpt3', 'instructgpt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa33175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d502209e",
   "metadata": {},
   "source": [
    "# POS + Parallel _ CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "712a8402",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(df['Features'])\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "4264f827",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fbada584",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_tfidf, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c3fe6009",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = X_train_tfidf.shape[1]\n",
    "input_shape = (max_len,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "eec9f90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filters = 64\n",
    "kernel_sizes = [3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3c37bccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.keras.layers.Input(shape=input_shape)\n",
    "reshape_layer = tf.keras.layers.Reshape((max_len, 1))(input_layer)\n",
    "conv_layers = []\n",
    "for kernel_size in kernel_sizes:\n",
    "    conv_layer = tf.keras.layers.Conv1D(filters=num_filters, kernel_size=kernel_size, activation='relu')(reshape_layer)\n",
    "    pool_layer = tf.keras.layers.MaxPooling1D(pool_size=max_len - kernel_size + 1)(conv_layer)\n",
    "    flatten_layer = tf.keras.layers.Flatten()(pool_layer)\n",
    "    conv_layers.append(flatten_layer)\n",
    "concat_layer = tf.keras.layers.concatenate(conv_layers, axis=-1)\n",
    "output_layer = tf.keras.layers.Dense(len(le.classes_), activation='softmax')(concat_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "390787d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=input_layer, outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "38d031af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "90fbd171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 1.0627 - accuracy: 0.6303 - val_loss: 1.1329 - val_accuracy: 0.6157\n",
      "Epoch 2/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 1.0569 - accuracy: 0.6302 - val_loss: 1.1139 - val_accuracy: 0.6162\n",
      "Epoch 3/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 1.0505 - accuracy: 0.6362 - val_loss: 1.1361 - val_accuracy: 0.5954\n",
      "Epoch 4/20\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 1.0464 - accuracy: 0.6361 - val_loss: 1.1144 - val_accuracy: 0.6039\n",
      "Epoch 5/20\n",
      "235/235 [==============================] - 1s 3ms/step - loss: 1.0429 - accuracy: 0.6399 - val_loss: 1.1001 - val_accuracy: 0.6226\n",
      "Epoch 6/20\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 1.0379 - accuracy: 0.6382 - val_loss: 1.0996 - val_accuracy: 0.6183\n",
      "Epoch 7/20\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 1.0367 - accuracy: 0.6410 - val_loss: 1.0966 - val_accuracy: 0.6167\n",
      "Epoch 8/20\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 1.0293 - accuracy: 0.6466 - val_loss: 1.0904 - val_accuracy: 0.6167\n",
      "Epoch 9/20\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 1.0270 - accuracy: 0.6397 - val_loss: 1.0900 - val_accuracy: 0.6210\n",
      "Epoch 10/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 1.0208 - accuracy: 0.6467 - val_loss: 1.0866 - val_accuracy: 0.6274\n",
      "Epoch 11/20\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 1.0169 - accuracy: 0.6443 - val_loss: 1.0905 - val_accuracy: 0.6162\n",
      "Epoch 12/20\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 1.0128 - accuracy: 0.6458 - val_loss: 1.0790 - val_accuracy: 0.6311\n",
      "Epoch 13/20\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 1.0098 - accuracy: 0.6527 - val_loss: 1.0692 - val_accuracy: 0.6301\n",
      "Epoch 14/20\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 1.0057 - accuracy: 0.6485 - val_loss: 1.0719 - val_accuracy: 0.6242\n",
      "Epoch 15/20\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 1.0030 - accuracy: 0.6497 - val_loss: 1.0672 - val_accuracy: 0.6263\n",
      "Epoch 16/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 1.0026 - accuracy: 0.6522 - val_loss: 1.0633 - val_accuracy: 0.6274\n",
      "Epoch 17/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.9967 - accuracy: 0.6525 - val_loss: 1.0615 - val_accuracy: 0.6327\n",
      "Epoch 18/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.9925 - accuracy: 0.6550 - val_loss: 1.0620 - val_accuracy: 0.6295\n",
      "Epoch 19/20\n",
      "235/235 [==============================] - 0s 2ms/step - loss: 0.9906 - accuracy: 0.6542 - val_loss: 1.0591 - val_accuracy: 0.6429\n",
      "Epoch 20/20\n",
      "235/235 [==============================] - 1s 2ms/step - loss: 0.9884 - accuracy: 0.6527 - val_loss: 1.0522 - val_accuracy: 0.6370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20c27515f90>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train.toarray(), y_train, epochs=20, batch_size=32, validation_data=(X_val.toarray(), y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f4df9ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 0s 850us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "25c0d98c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  4,  4, ...,  1, 10,  7], dtype=int64)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "eea36605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  5,  4, ...,  3, 10,  4])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "81e65883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[191   0   4   1   1   0   2   0   1   6   8]\n",
      " [  5  78   1  39   9  44  11   9   9   3   1]\n",
      " [  2   0 213   0   0   0   2   0   0   0   0]\n",
      " [  0  40   0 121  14  20   2  10   5   1   0]\n",
      " [  3   1   1  17 105   0  32  37  20   1   0]\n",
      " [  1  42   4  16   4 125   9  11   4   4   2]\n",
      " [  3   0   9   5  35   2 135  13  17   0   1]\n",
      " [  1  12   0  15  53   3  18  80  16   4   0]\n",
      " [  1   5   0   4  12   0  44   4 128   8   0]\n",
      " [  4   2   0   5   2   0   1   0   8 183  10]\n",
      " [ 16   0   1   1   0   1   2   0   1  14 175]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c00f9fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ctrl       0.84      0.89      0.87       214\n",
      "        fair       0.43      0.37      0.40       209\n",
      "         gpt       0.91      0.98      0.95       217\n",
      "        gpt2       0.54      0.57      0.55       213\n",
      "        gpt3       0.45      0.48      0.46       217\n",
      "      grover       0.64      0.56      0.60       222\n",
      "       human       0.52      0.61      0.56       220\n",
      " instructgpt       0.49      0.40      0.44       202\n",
      "        pplm       0.61      0.62      0.62       206\n",
      "         xlm       0.82      0.85      0.83       215\n",
      "       xlnet       0.89      0.83      0.86       211\n",
      "\n",
      "    accuracy                           0.65      2346\n",
      "   macro avg       0.65      0.65      0.65      2346\n",
      "weighted avg       0.65      0.65      0.65      2346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "bcfeb3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('POS_Parallel_CNN.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187262bd",
   "metadata": {},
   "source": [
    "# Task - 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "1b5d23d2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 0s 869us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 8, ..., 7, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = tf.keras.models.load_model('POS_Parallel_CNN.h5')\n",
    "y_pred = loaded_model.predict(X_test.toarray())\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "0b20170c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = le.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "36d89dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = d2['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "d3736404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ctrl' 'ctrl' 'ctrl' ... 'instructgpt' 'instructgpt' 'instructgpt']\n",
      "['ctrl' 'ctrl' 'pplm' ... 'instructgpt' 'gpt2' 'gpt3']\n"
     ]
    }
   ],
   "source": [
    "print(actual)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "733458cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ctrl       0.86      0.91      0.88       500\n",
      "        fair       0.45      0.38      0.41       500\n",
      "         gpt       0.94      0.97      0.96       500\n",
      "        gpt2       0.56      0.54      0.55       500\n",
      "      grover       0.61      0.60      0.61       500\n",
      " instructgpt       0.53      0.44      0.48       500\n",
      "        pplm       0.71      0.65      0.68       500\n",
      "         xlm       0.84      0.85      0.85       500\n",
      "       xlnet       0.91      0.80      0.85       500\n",
      "        gpt3       0.50      0.46      0.48       500\n",
      " instructgpt       0.53      0.44      0.48       500\n",
      "\n",
      "   micro avg       0.68      0.64      0.66      5500\n",
      "   macro avg       0.68      0.64      0.66      5500\n",
      "weighted avg       0.68      0.64      0.66      5500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(actual, y_pred, labels=['ctrl','fair','gpt','gpt2','grover','instructgpt','pplm','xlm','xlnet','gpt3', 'instructgpt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624f50d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "786f4c24",
   "metadata": {},
   "source": [
    "# POS + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "5991b7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train_counts = vectorizer.fit_transform(df['Features'])\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "19a3b666",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "y = le.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "c3779054",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train_tfidf, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "43a8f352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9380, 76), (2346, 76), (9380,), (2346,))"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "69781356",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "d23d854c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective=&#x27;multi:softprob&#x27;, predictor=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              objective='multi:softprob', predictor=None, ...)"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(X_train.toarray(), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "6e32814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "9cf45dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb.predict(X_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "2f3bb9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['gpt3', 'grover', 'gpt3', ..., 'gpt2', 'xlnet', 'gpt3'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = le.inverse_transform(y_pred)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "8c1877e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = le.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "d9cf1d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['human', 'grover', 'gpt3', ..., 'gpt2', 'xlnet', 'gpt3'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "25da6603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.840153452685422\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "e92226b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ctrl       0.97      1.00      0.98       214\n",
      "        fair       0.67      0.65      0.66       209\n",
      "         gpt       0.98      0.98      0.98       217\n",
      "        gpt2       0.80      0.77      0.79       213\n",
      "        gpt3       0.66      0.67      0.67       217\n",
      "      grover       0.83      0.80      0.82       222\n",
      "       human       0.81      0.75      0.78       220\n",
      " instructgpt       0.70      0.73      0.72       202\n",
      "        pplm       0.84      0.92      0.88       206\n",
      "         xlm       0.99      1.00      0.99       215\n",
      "       xlnet       0.99      0.98      0.98       211\n",
      "\n",
      "    accuracy                           0.84      2346\n",
      "   macro avg       0.84      0.84      0.84      2346\n",
      "weighted avg       0.84      0.84      0.84      2346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4719d9e",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "940355d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_task_3 = vectorizer.transform(T1['Features'])\n",
    "X_test_task_3 = tfidf_transformer.transform(X_test_task_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "9cbd64dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = xgb.predict(X_test_task_3.toarray())\n",
    "# y_pred = np.argmax(y_pred, axis=1)\n",
    "# y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "befdbbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = le.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "be865a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = d2['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "29630303",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ctrl' 'ctrl' 'ctrl' ... 'instructgpt' 'instructgpt' 'instructgpt']\n",
      "['ctrl' 'ctrl' 'ctrl' ... 'gpt3' 'instructgpt' 'instructgpt']\n"
     ]
    }
   ],
   "source": [
    "print(actual)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "ab1a2269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ctrl       0.99      1.00      1.00       500\n",
      "        fair       0.94      0.94      0.94       500\n",
      "         gpt       1.00      1.00      1.00       500\n",
      "        gpt2       0.96      0.96      0.96       500\n",
      "      grover       0.97      0.96      0.96       500\n",
      " instructgpt       0.95      0.94      0.94       500\n",
      "        pplm       0.98      0.98      0.98       500\n",
      "         xlm       1.00      1.00      1.00       500\n",
      "       xlnet       1.00      0.99      0.99       500\n",
      "        gpt3       0.96      0.93      0.94       500\n",
      " instructgpt       0.95      0.94      0.94       500\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      5500\n",
      "   macro avg       0.97      0.97      0.97      5500\n",
      "weighted avg       0.97      0.97      0.97      5500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(actual, y_pred, labels=['ctrl','fair','gpt','gpt2','grover','instructgpt','pplm','xlm','xlnet','gpt3', 'instructgpt']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dcb54dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
